{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Forward Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use jit, numba and C++ to optimize the forward step in Variational autoencoder. Hopefully the performance will get close to using tensorflow only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.python.client import timeline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from vae_sta663 import *\n",
    "from misc_sta663 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "config = {}\n",
    "config['x_in'] = 784\n",
    "config['encoder_1'] = 500\n",
    "config['encoder_2'] = 500\n",
    "config['decoder_1'] = 500\n",
    "config['decoder_2'] = 500\n",
    "config['z'] = 20\n",
    "\n",
    "encoder_weights, _ = init_weights(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform tensors to numpy array\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "encoder_weights_np = {}\n",
    "encoder_weights_np['h1'] = sess.run(encoder_weights['h1'])\n",
    "encoder_weights_np['h2'] = sess.run(encoder_weights['h2'])\n",
    "encoder_weights_np['mu'] = sess.run(encoder_weights['mu'])\n",
    "encoder_weights_np['sigma'] = sess.run(encoder_weights['sigma'])\n",
    "encoder_weights_np['b1'] = sess.run(encoder_weights['b1'])\n",
    "encoder_weights_np['b2'] = sess.run(encoder_weights['b2'])\n",
    "encoder_weights_np['bias_mu'] = sess.run(encoder_weights['bias_mu'])\n",
    "encoder_weights_np['bias_sigma'] = sess.run(encoder_weights['bias_sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(mnist, n_samples) = mnist_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_sample, _ = mnist.train.next_batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_z(x, encoder_weights):\n",
    "    \"\"\"\n",
    "    Compute mean and sigma of z\n",
    "    \"\"\"\n",
    "    layer_1 = tf.nn.softplus(tf.add(tf.matmul(x, encoder_weights['h1']), encoder_weights['b1']))\n",
    "    layer_2 = tf.nn.softplus(tf.add(tf.matmul(layer_1, encoder_weights['h2']), encoder_weights['b2']))\n",
    "    z_mean = tf.add(tf.matmul(layer_2, encoder_weights['mu']), encoder_weights['bias_mu'])\n",
    "    z_sigma = tf.add(tf.matmul(layer_2, encoder_weights['sigma']), encoder_weights['bias_sigma'])\n",
    "    \n",
    "    return(z_mean, z_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_sample_tf = tf.constant(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit -n10 -r3 sess.run(forward_z(x_sample_tf, encoder_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Numpy without Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_z_raw(x, encoder_weights):\n",
    "    \"\"\"\n",
    "    Compute mean and sigma of z using numpy without any optimization\n",
    "    \"\"\"\n",
    "    layer_1 = np.log(np.exp(x_sample @ encoder_weights_np['h1'] + encoder_weights_np['b1']) + 1)\n",
    "    layer_2 = np.log(np.exp(layer_1 @ encoder_weights_np['h2'] + encoder_weights_np['b2']) + 1)\n",
    "    z_mean = (layer_2 @ encoder_weights_np['mu'] + encoder_weights_np['bias_mu'])\n",
    "    z_sigma = (layer_2 @ encoder_weights_np['sigma'] + encoder_weights_np['bias_sigma'])\n",
    "    \n",
    "    return(z_mean, z_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit -n10 -r3 forward_z_raw(x_sample, encoder_weights_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(sess.run(forward_z(x_sample_tf, encoder_weights)), forward_z_raw(x_sample, encoder_weights_np), \n",
    "                               decimal=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Numpy with Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import jit, vectorize, float32, float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@jit('float32[:,:](float64[:,:],float64[:,:])')\n",
    "def mat_mul(A, B):\n",
    "    m, n = A.shape\n",
    "    n, p = B.shape\n",
    "    C = np.zeros((m, p))\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            for k in range(n):\n",
    "                C[i,j] += A[i,k] * B[k,j]\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parallel version of soft plus function\n",
    "@vectorize([float64(float64)], target='parallel')\n",
    "def soft_plus(x):\n",
    "    \"\"\"\n",
    "    Vectorize version of numba\n",
    "    \"\"\"\n",
    "    return np.log(np.exp(x) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit('UniTuple(float64[:,:], 2)(float64[:],float64[:,:],float64[:,:],float64[:,:],float64[:,:],float64[:,:],float64[:,:],float64[:,:],float64[:,:])')\n",
    "def forward_z_numba(x, encoder_weights_h1, encoder_weights_h2, encoder_weights_b1, encoder_weights_b2, encoder_weights_mu, \n",
    "                  encoder_weights_bias_mu, encoder_weights_sigma, encoder_weights_bias_sigma):\n",
    "    \"\"\"\n",
    "    Compute mean and sigma of z using numpy without any optimization\n",
    "    \"\"\"\n",
    "    layer_1 = soft_plus(mat_mul(x, encoder_weights_h1) + encoder_weights_b1)\n",
    "    layer_2 = soft_plus(mat_mul(layer_1, encoder_weights_h2) + encoder_weights_b2)\n",
    "    z_mean = (mat_mul(layer_2, encoder_weights_mu) + encoder_weights_bias_mu)\n",
    "    z_sigma = (mat_mul(layer_2, encoder_weights_sigma) + encoder_weights_bias_sigma)\n",
    "    \n",
    "    return(z_mean, z_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -n10 -r3 \n",
    "forward_z_numba(x_sample, encoder_weights_np['h1'], encoder_weights_np['h2'], encoder_weights_np['b1'], \n",
    "              encoder_weights_np['b2'], encoder_weights_np['mu'], encoder_weights_np['bias_mu'], \n",
    "              encoder_weights_np['sigma'], encoder_weights_np['bias_sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(sess.run(forward_z(x_sample_tf, encoder_weights)), \n",
    "                               forward_z_numba(x_sample, encoder_weights_np['h1'], encoder_weights_np['h2'], \n",
    "                                             encoder_weights_np['b1'], encoder_weights_np['b2'], encoder_weights_np['mu'], \n",
    "                                             encoder_weights_np['bias_mu'], encoder_weights_np['sigma'], \n",
    "                                             encoder_weights_np['bias_sigma']), decimal=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "cimport cython\n",
    "import numpy as np\n",
    "from libc.math cimport exp, log\n",
    "\n",
    "@cython.wraparound(False)\n",
    "@cython.boundscheck(False)\n",
    "cdef double[:,:] mat_mul_cython(double[:,:] A, double[:,:] B):\n",
    "    \"\"\"Matrix multiply function. Cythonize\"\"\"\n",
    "    cdef int m = A.shape[0]\n",
    "    cdef int n = A.shape[1]\n",
    "    cdef int p = B.shape[1]\n",
    "    cdef int i,j,k\n",
    "    cdef double[:,:] C = np.zeros((m, p))\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            for k in range(n):\n",
    "                C[i,j] += A[i,k] * B[k,j]\n",
    "    return C\n",
    "\n",
    "@cython.wraparound(False)\n",
    "@cython.boundscheck(False)\n",
    "cdef double[:,:] mat_add_cython(double[:,:] A, double[:] B):\n",
    "    \"\"\"Matrix multiply function. Cythonize\"\"\"\n",
    "    cdef int m = A.shape[0]\n",
    "    cdef int n = A.shape[1]\n",
    "    cdef int i,j\n",
    "    cdef double[:,:] C = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            C[i,j] = A[i,j] + B[j]\n",
    "    return C\n",
    "\n",
    "@cython.wraparound(False)\n",
    "@cython.boundscheck(False)\n",
    "cdef double[:,:] soft_plus_cython(double[:,:] x):\n",
    "    cdef int m = x.shape[0]\n",
    "    cdef int n = x.shape[1]\n",
    "    cdef double[:,:] y = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            y[i,j] = log(exp(x[i,j])+1)\n",
    "    return y\n",
    "\n",
    "@cython.wraparound(False)\n",
    "@cython.boundscheck(False)\n",
    "def forward_z_cython(double[:,:] x, double[:,:] encoder_weights_h1, double[:,:] encoder_weights_h2, \n",
    "                     double[:] encoder_weights_b1, double[:] encoder_weights_b2, double [:,:] encoder_weights_mu, \n",
    "                     double[:] encoder_weights_bias_mu, double[:,:] encoder_weights_sigma, \n",
    "                     double[:] encoder_weights_bias_sigma):\n",
    "    \"\"\"\n",
    "    Compute mean and sigma of z using numpy with cython optimization\n",
    "    \"\"\"\n",
    "    cdef double[:,:] layer_1 = soft_plus_cython(mat_add_cython(mat_mul_cython(x, encoder_weights_h1), encoder_weights_b1))\n",
    "    cdef double[:,:] layer_2 = soft_plus_cython(mat_add_cython(mat_mul_cython(layer_1, encoder_weights_h2), encoder_weights_b2))\n",
    "    cdef double[:,:] z_mean = mat_add_cython(mat_mul_cython(layer_2, encoder_weights_mu), encoder_weights_bias_mu)\n",
    "    cdef double[:,:] z_sigma = mat_add_cython(mat_mul_cython(layer_2, encoder_weights_sigma), encoder_weights_bias_sigma)\n",
    "    \n",
    "    return(np.array(z_mean), np.array(z_sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_sample = x_sample.astype(np.float64)\n",
    "encoder_weights_np['h1'] = encoder_weights_np['h1'].astype(np.float64)\n",
    "encoder_weights_np['h2'] = encoder_weights_np['h2'].astype(np.float64)\n",
    "encoder_weights_np['b1'] = encoder_weights_np['b1'].astype(np.float64)\n",
    "encoder_weights_np['b2'] = encoder_weights_np['b2'].astype(np.float64)\n",
    "encoder_weights_np['mu'] = encoder_weights_np['mu'].astype(np.float64)\n",
    "encoder_weights_np['bias_mu'] = encoder_weights_np['bias_mu'].astype(np.float64)\n",
    "encoder_weights_np['sigma'] = encoder_weights_np['sigma'].astype(np.float64)\n",
    "encoder_weights_np['bias_sigma'] = encoder_weights_np['bias_sigma'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -n10 -r3 \n",
    "forward_z_cython(x_sample, encoder_weights_np['h1'], encoder_weights_np['h2'], encoder_weights_np['b1'], \n",
    "              encoder_weights_np['b2'], encoder_weights_np['mu'], encoder_weights_np['bias_mu'], \n",
    "              encoder_weights_np['sigma'], encoder_weights_np['bias_sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(sess.run(forward_z(x_sample_tf, encoder_weights)), \n",
    "                               forward_z_cython(x_sample, encoder_weights_np['h1'], encoder_weights_np['h2'], \n",
    "                                             encoder_weights_np['b1'], encoder_weights_np['b2'], encoder_weights_np['mu'], \n",
    "                                             encoder_weights_np['bias_mu'], encoder_weights_np['sigma'], \n",
    "                                             encoder_weights_np['bias_sigma']), decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
